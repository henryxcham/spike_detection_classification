{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57926404",
   "metadata": {},
   "source": [
    "# 2. spike classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Get the absolute path of the parent directory (project root)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utils import load_and_concatenate_npy, normalize_data\n",
    "from src.models import CNNClassifier, GRUClassifier\n",
    "from src.evaluate import evaluate_model\n",
    "\n",
    "from scripts.train_cnn import train_cnn\n",
    "from scripts.train_gru import train_gru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea36169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting CNN Model Training ---\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_background_9.npy with shape (5704, 42)\n",
      "Successfully loaded file: ../data/spikes//channel_background_16.npy with shape (4324, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_background_33.npy with shape (2934, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (12962, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_9.npy with shape (1079, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_16.npy with shape (253, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_33.npy with shape (1159, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (2491, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_background_11.npy with shape (6835, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (6835, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_11.npy with shape (819, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (819, 42)\n",
      "Starting cnn training loop...\n",
      "Epoch [1/20], Train Loss: 0.3225, Valid F1: 0.9242\n",
      "Model saved with a new best F1 score of 0.9242\n",
      "Epoch [2/20], Train Loss: 0.1937, Valid F1: 0.9413\n",
      "Model saved with a new best F1 score of 0.9413\n",
      "Epoch [3/20], Train Loss: 0.1838, Valid F1: 0.9468\n",
      "Model saved with a new best F1 score of 0.9468\n",
      "Epoch [4/20], Train Loss: 0.1728, Valid F1: 0.9357\n",
      "Validation F1 did not improve. Patience: 1/5\n",
      "Epoch [5/20], Train Loss: 0.1725, Valid F1: 0.9395\n",
      "Validation F1 did not improve. Patience: 2/5\n",
      "Epoch [6/20], Train Loss: 0.1636, Valid F1: 0.9422\n",
      "Validation F1 did not improve. Patience: 3/5\n",
      "Epoch [7/20], Train Loss: 0.1618, Valid F1: 0.9393\n",
      "Validation F1 did not improve. Patience: 4/5\n",
      "Epoch [8/20], Train Loss: 0.1555, Valid F1: 0.9480\n",
      "Model saved with a new best F1 score of 0.9480\n",
      "Epoch [9/20], Train Loss: 0.1562, Valid F1: 0.9189\n",
      "Validation F1 did not improve. Patience: 1/5\n",
      "Epoch [10/20], Train Loss: 0.1518, Valid F1: 0.9398\n",
      "Validation F1 did not improve. Patience: 2/5\n",
      "Epoch [11/20], Train Loss: 0.1566, Valid F1: 0.9468\n",
      "Validation F1 did not improve. Patience: 3/5\n",
      "Epoch [12/20], Train Loss: 0.1480, Valid F1: 0.9449\n",
      "Validation F1 did not improve. Patience: 4/5\n",
      "Epoch [13/20], Train Loss: 0.1505, Valid F1: 0.9363\n",
      "Validation F1 did not improve. Patience: 5/5\n",
      "\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# 1. Train the Models\n",
    "# This will run the training scripts and save the best models to the project root.\n",
    "print(\"--- Starting CNN Model Training ---\")\n",
    "train_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4538f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting GRU Model Training ---\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_background_9.npy with shape (5704, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_background_16.npy with shape (4324, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_background_33.npy with shape (2934, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (12962, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_9.npy with shape (1079, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_16.npy with shape (253, 42)\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_33.npy with shape (1159, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (2491, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_background_11.npy with shape (6835, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (6835, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_11.npy with shape (819, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (819, 42)\n",
      "Starting gru training loop...\n",
      "Epoch [1/20], Train Loss: 0.3045, Valid F1: 0.8925\n",
      "Model saved with a new best F1 score of 0.8925\n",
      "Epoch [2/20], Train Loss: 0.1686, Valid F1: 0.9274\n",
      "Model saved with a new best F1 score of 0.9274\n",
      "Epoch [3/20], Train Loss: 0.1432, Valid F1: 0.9519\n",
      "Model saved with a new best F1 score of 0.9519\n",
      "Epoch [4/20], Train Loss: 0.1398, Valid F1: 0.9344\n",
      "Validation F1 did not improve. Patience: 1/5\n",
      "Epoch [5/20], Train Loss: 0.1353, Valid F1: 0.9448\n",
      "Validation F1 did not improve. Patience: 2/5\n",
      "Epoch [6/20], Train Loss: 0.1349, Valid F1: 0.9474\n",
      "Validation F1 did not improve. Patience: 3/5\n",
      "Epoch [7/20], Train Loss: 0.1326, Valid F1: 0.9365\n",
      "Validation F1 did not improve. Patience: 4/5\n",
      "Epoch [8/20], Train Loss: 0.1331, Valid F1: 0.9387\n",
      "Validation F1 did not improve. Patience: 5/5\n",
      "\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting GRU Model Training ---\")\n",
    "train_gru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050a04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading and Preparation (for evaluation)\n",
    "background_file_paths_test = [\n",
    "    '../data/spikes/channel_background_40.npy'\n",
    "]\n",
    "spikes_file_paths_test = [\n",
    "    '../data/spikes/channel_spikes_40.npy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd587f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataset(background_paths, spikes_paths):\n",
    "    background_array = load_and_concatenate_npy(background_paths)\n",
    "    spikes_array = load_and_concatenate_npy(spikes_paths)\n",
    "    \n",
    "    X_np = np.concatenate([background_array, spikes_array], axis=0)\n",
    "    y_np = np.concatenate([\n",
    "        np.zeros(background_array.shape[0]), \n",
    "        np.ones(spikes_array.shape[0])\n",
    "    ], axis=0)\n",
    "    \n",
    "    X_tensor = torch.from_numpy(X_np).float()\n",
    "    y_tensor = torch.from_numpy(y_np).long()\n",
    "    return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32180ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_background_40.npy with shape (4073, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (4073, 42)\n",
      "Loading data...\n",
      "Successfully loaded file: ../data/spikes/channel_spikes_40.npy with shape (108, 42)\n",
      "\n",
      "All arrays concatenated. Final shape: (108, 42)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_test_dataset(background_file_paths_test, spikes_file_paths_test)\n",
    "train_mean = X_test.mean()\n",
    "train_std = X_test.std()\n",
    "X_test_normalized = normalize_data(X_test, train_mean, train_std).unsqueeze(1)\n",
    "test_dataset = TensorDataset(X_test_normalized, y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d2fd60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CNN model...\n",
      "\n",
      "--- Best Model Test Metrics ---\n",
      "Accuracy: 0.9823\n",
      "Macro Precision: 0.7967\n",
      "Macro Recall: 0.9909\n",
      "Macro F1 Score: 0.8678\n",
      "CPU times: total: 312 ms\n",
      "Wall time: 411 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluate CNN model\n",
    "cnn_model = CNNClassifier(input_size=X_test.shape[1], num_classes=2)\n",
    "print(\"Evaluating CNN model...\")\n",
    "evaluate_model(cnn_model, '../model/best_cnn_model.pth', test_loader, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc1791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GRU model...\n",
      "\n",
      "--- Best Model Test Metrics ---\n",
      "Accuracy: 0.9735\n",
      "Macro Precision: 0.7461\n",
      "Macro Recall: 0.9729\n",
      "Macro F1 Score: 0.8202\n",
      "CPU times: total: 922 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluate GRU model\n",
    "gru_model = GRUClassifier(input_size=X_test.shape[1], num_classes=2)\n",
    "print(\"\\nEvaluating GRU model...\")\n",
    "evaluate_model(gru_model, '../model/best_gru_model.pth', test_loader, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cbf930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_detection_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
